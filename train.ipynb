{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257, # Vocabulary size\n",
    "\"context_length\": 256, # Context length\n",
    "\"emb_dim\": 768, # Embedding dimension\n",
    "\"n_heads\": 12, # Number of attention heads\n",
    "\"n_layers\": 12, # Number of layers\n",
    "\"drop_rate\": 0.1, # Dropout rate\n",
    "\"qkv_bias\": False # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efb2489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs are :\n",
      "tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n",
      "targets are :\n",
      "tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "from dataset import text_to_token_ids,token_ids_to_text\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text1 = \"every effort moves\"\n",
    "text2 = \"I really like\"\n",
    "\n",
    "text1_encoded = text_to_token_ids(text1,tokenizer)\n",
    "text2_encoded = text_to_token_ids(text2,tokenizer)\n",
    "\n",
    "inputs = torch.vstack((text1_encoded,text2_encoded))\n",
    "print(\"inputs are :\")\n",
    "print(inputs)\n",
    "\n",
    "target1 =  \" effort moves you\"\n",
    "target2 = \" really like chocolate\"\n",
    "\n",
    "target1_encoded = text_to_token_ids(target1,tokenizer)\n",
    "target2_encoded = text_to_token_ids(target2,tokenizer)\n",
    "\n",
    "targets = torch.vstack((target1_encoded,target2_encoded))\n",
    "print(\"targets are :\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc8b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "from llms import GPT2\n",
    "model = GPT2(GPT_CONFIG_124M)\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80ab9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[34484],\n",
      "         [25008],\n",
      "         [41386]],\n",
      "\n",
      "        [[40997],\n",
      "         [37162],\n",
      "         [23221]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b2bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: uriaJUSTPok√©\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4e6e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([1.0887e-05, 2.5004e-05, 2.1886e-05])\n",
      "Text 2: tensor([6.2089e-05, 8.4397e-06, 1.7906e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be98542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.4279, -10.5965, -10.7297,  -9.6869, -11.6826, -10.9304])\n",
      "tensor(10.8423)\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "avg_log_probas = torch.mean(log_probas) * -1 # -1 for NLL\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8beda51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ee3b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8423)\n",
      "tensor(51140.0547)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1787b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b6be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_point = int(0.9 * total_characters)\n",
    "\n",
    "data_train = text_data[:split_point]\n",
    "data_val = text_data[split_point:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2459a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataloader\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader(\n",
    "    data_train,\n",
    "    batch_size=2,\n",
    "    max_len=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = create_dataloader(\n",
    "    data_val,\n",
    "    batch_size=2,\n",
    "    max_len=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b10a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c878642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch) #(batch_size,context_len,vocab_size)\n",
    "\n",
    "    # we will use torch.nn.functional \n",
    "    # we must do some dimensional arrangements\n",
    "    # target has size of (batch_size,context_len)\n",
    "    # logits has size of #(batch_size,context_len,vocab_size)\n",
    "    # We must transform targets to (batch_size * context_len)\n",
    "    # We must transform logits to (batch_size * context_len, vocab_size)\n",
    "    # Look Example small for cell below\n",
    "\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73b13150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1315, -0.6948, -0.5823],\n",
      "         [ 1.0035, -1.4613,  0.8985]],\n",
      "\n",
      "        [[ 0.6210, -0.9679,  0.6740],\n",
      "         [-1.2828, -0.5097,  0.1464]]])\n",
      "-----------------------------\n",
      "tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([[ 0.1315, -0.6948, -0.5823],\n",
      "        [ 1.0035, -1.4613,  0.8985],\n",
      "        [ 0.6210, -0.9679,  0.6740],\n",
      "        [-1.2828, -0.5097,  0.1464]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "context_len = 2\n",
    "vocab_size = 3\n",
    "\n",
    "logits = torch.randn((batch_size,context_len,vocab_size))\n",
    "targets = torch.randint(0,vocab_size,(batch_size,context_len))\n",
    "\n",
    "print(logits)\n",
    "print(\"-----------------------------\")\n",
    "print(targets)\n",
    "\n",
    "print(targets.flatten())\n",
    "print(logits.flatten(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d393eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        # no data\n",
    "        return float(\"nan\")\n",
    "    elif num_batches == None:\n",
    "        # if num_batches is 0 then whole data\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(len(data_loader),num_batches)\n",
    "    \n",
    "\n",
    "    for i,(inp,target) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(inp, target, model, device)\n",
    "            total_loss = loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00372ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.047321319580078\n",
      "Validation loss: 10.998329162597656\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31317988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
